package v1

import (
	"bytes"
	"fmt"
	"strconv"
	"strings"
	"unicode"

	"github.com/gofiber/fiber/v2"

	"github.com/pgconfig/api/pkg/category"
	"github.com/pgconfig/api/pkg/config"
	"github.com/pgconfig/api/pkg/docs"
	"github.com/pgconfig/api/pkg/rules"
)

// GetConfig is a function to that computes the input and suggests a tuning configuration
// @Summary Get Configuration
// @Description computes the input and suggests a tuning configuration
// @Accept json
// @Produce json
// @Param pg_version query string false "PostgreSQL Version" default(13)
// @Param total_ram query string false "Total dedicated memory to PostgreSQL" default(2GB)
// @Param max_connections query integer false "Total expected number of connections" default(100)
// @Param environment_name query string false "Application profile of the server" Enums(WEB,OLTP,DW,Mixed,Desktop) default(WEB)
// @Param os_type query string false "Type of operating system used" Enums(linux,windows,unix) default(linux)
// @Param arch query string false "server architecture" Enums(386,amd64,arm,arm64) default(amd64)
// @Param drive_type query string false "default storage type" Enums(HDD,SSD,SAN) default(HDD)
// @Param cpus query integer false "Total CPUs available" default(2)
// @Param format query string false "Output format" Enums(json,alter_system,conf) default(json)
// @Param show_doc query string false "Show Documentation args" Enums(true,false) default(false)
// @Param include_pgbadger query string false "Add pgbadger configuration" Enums(true,false) default(false)
// @Param log_format query string false "Defines the log_format to be used" Enums(stderr,csvlog,syslog) default(stderr)
// @Success 200 {object} ResponseHTTP{}
// @Router /v1/tuning/get-config [get]
func GetConfig(c *fiber.Ctx) error {

	args, err := parseConfigArgs(c)

	if err != nil {
		return fmt.Errorf("could not parse args: %w", err)
	}

	finalData, err := processConfig(c, args)

	if err != nil {
		return fmt.Errorf("could not process config: %w", err)
	}

	switch args.outFormat {
	case "alter_system":
		return c.SendString(formatConf(c, args.outFormat, finalData))
	case "conf":
		return c.SendString(formatConf(c, args.outFormat, finalData))
	default:
		return c.JSON(v1Reponse(c, finalData))
	}
}

func processConfig(c *fiber.Ctx, args *configArgs) ([]outputCategory, error) {
	input := *config.NewInput(
		args.osType,
		args.arch,
		args.totalRAM,
		args.cpuCount,
		args.envName,
		args.driveType,
		args.maxConn,
		args.pgVersion)

	tune, err := rules.Compute(input)

	if err != nil {
		return nil, err
	}

	output := addDocTORules(docs.FormatVer(args.pgVersion), args.showDoc)

	return setValues(output, tune, args.includePgbadger, args.logFormat), nil

}

func parseConfigArgs(c *fiber.Ctx) (*configArgs, error) {

	pgVersion, err := strconv.ParseFloat(c.Query("pg_version", defaultPgVersion), 32)

	if err != nil {
		return nil, err
	}
	maxConn, err := strconv.Atoi(c.Query("max_connections", "100"))

	if err != nil {
		return nil, err
	}

	cpuCount, err := strconv.Atoi(c.Query("cpus", "2"))

	if err != nil {
		return nil, err
	}

	return &configArgs{
		pgVersion:       float32(pgVersion),
		totalRAM:        parseRAM(strings.ToUpper(c.Query("total_ram", "2GB"))),
		maxConn:         maxConn,
		envName:         c.Query("environment_name", "WEB"),
		osType:          c.Query("os_type", "linux"),
		arch:            c.Query("arch", "amd64"),
		driveType:       c.Query("drive_type", "HDD"),
		cpuCount:        cpuCount,
		outFormat:       c.Query("format", "json"),
		showDoc:         c.Query("show_doc", "false") == "true",
		includePgbadger: c.Query("include_pgbadger", "false") == "true",
		logFormat:       c.Query("log_format", "stderr"),
	}, nil
}

type configArgs struct {
	pgVersion       float32
	totalRAM        config.Byte
	maxConn         int
	envName         string
	osType          string
	arch            string
	driveType       string
	cpuCount        int
	outFormat       string
	showDoc         bool
	includePgbadger bool
	logFormat       string
}

type templateData struct {
	OutputData []outputCategory
	URL        string
}

func formatConf(c *fiber.Ctx, format string, output []outputCategory) string {

	var comment string

	switch format {
	case "alter_system":
		comment = "--"
	default:
		comment = "#"
	}

	var b bytes.Buffer

	b.WriteString(fmt.Sprintf("%s Generated by PGConfig 3.0 alpha\n", fillComment(1, comment)))
	b.WriteString(fmt.Sprintf("%s %s%s\n", fillComment(2, comment), c.BaseURL(), c.OriginalURL()))
	b.WriteString("\n")

	for cat := 0; cat < len(output); cat++ {
		b.WriteString(fmt.Sprintf("%s %s\n", fillComment(1, comment), output[cat].Description))
		for p := 0; p < len(output[cat].Parameters); p++ {

			if output[cat].Parameters[p].Notes.Comment != "" {
				b.WriteString(fmt.Sprintf("\n%s %s\n", fillComment(1, comment), output[cat].Parameters[p].Notes.Comment))

			}

			if format == "alter_system" {
				b.WriteString(fmt.Sprintf("ALTER SYSTEM SET %s TO '%s';\n", output[cat].Parameters[p].Name, output[cat].Parameters[p].Value))
				continue
			}
			b.WriteString(fmt.Sprintf("%s = '%s'\n", output[cat].Parameters[p].Name, output[cat].Parameters[p].Value))
		}
		b.WriteString("\n")
	}

	return b.String()
}

func fillComment(qtd int, comment string) string {
	var b bytes.Buffer

	for i := 0; i < qtd; i++ {
		b.WriteString(comment)
	}

	return b.String()
}

func deleteCat(cats []outputCategory, name string) []outputCategory {
	var out []outputCategory

	for c := 0; c < len(cats); c++ {
		if cats[c].Name != name {
			out = append(out, cats[c])
		}
	}

	return out
}

func processPgbadgerCats(output []outputCategory, addPgbadger bool, logFormat string) []outputCategory {
	catsToDelete := []string{}
	if !addPgbadger {
		for c := 0; c < len(output); c++ {
			if strings.HasPrefix(output[c].Name, "log_related") {
				catsToDelete = append(catsToDelete, output[c].Name)
			}
		}
	} else {
		for c := 0; c < len(output); c++ {
			if strings.HasPrefix(output[c].Name, "log_related") {
				if output[c].Name != "log_related" &&
					output[c].Name != fmt.Sprintf("log_related_%s_config", logFormat) {
					catsToDelete = append(catsToDelete, output[c].Name)
				}
			}
		}
	}

	for i := 0; i < len(catsToDelete); i++ {
		output = deleteCat(output, catsToDelete[i])
	}

	return output
}

func setValues(output []outputCategory, tune *category.ExportCfg, addPgbadger bool, logFormat string) []outputCategory {

	output = processPgbadgerCats(output, addPgbadger, logFormat)

	for c := 0; c < len(output); c++ {
		for p := 0; p < len(output[c].Parameters); p++ {
			switch output[c].Parameters[p].Name {

			// Memory Config
			case "shared_buffers":
				output[c].Parameters[p].Value = tune.Memory.SharedBuffers.String()
			case "effective_cache_size":
				output[c].Parameters[p].Value = tune.Memory.EffectiveCacheSize.String()
			case "work_mem":
				output[c].Parameters[p].Value = tune.Memory.WorkMem.String()
			case "maintenance_work_mem":
				output[c].Parameters[p].Value = tune.Memory.MaintenanceWorkMem.String()

			// Checkpoint Config
			case "min_wal_size":
				output[c].Parameters[p].Value = tune.Checkpoint.MinWALSize.String()
			case "max_wal_size":
				output[c].Parameters[p].Value = tune.Checkpoint.MaxWALSize.String()
			case "checkpoint_completion_target":
				output[c].Parameters[p].Value = fmt.Sprintf("%.1f", tune.Checkpoint.CheckpointCompletionTarget)
			case "wal_buffers":
				output[c].Parameters[p].Value = tune.Checkpoint.WALBuffers.String()
			case "checkpoint_segments":
				output[c].Parameters[p].Value = fmt.Sprintf("%d", tune.Checkpoint.CheckpointSegments)

			// Network config
			case "listen_addresses":
				output[c].Parameters[p].Value = tune.Network.ListenAddresses
			case "max_connections":
				output[c].Parameters[p].Value = fmt.Sprintf("%d", tune.Network.MaxConnections)

			// Storage config
			case "random_page_cost":
				output[c].Parameters[p].Value = fmt.Sprintf("%.1f", tune.Storage.RandomPageCost)
			case "effective_io_concurrency":
				output[c].Parameters[p].Value = fmt.Sprintf("%d", tune.Storage.EffectiveIOConcurrency)

			// workers
			case "max_parallel_workers":
				output[c].Parameters[p].Value = fmt.Sprintf("%d", tune.Worker.MaxParallelWorkers)
			case "max_parallel_workers_per_gather":
				output[c].Parameters[p].Value = fmt.Sprintf("%d", tune.Worker.MaxParallelWorkerPerGather)
			case "max_worker_processes":
				output[c].Parameters[p].Value = fmt.Sprintf("%d", tune.Worker.MaxWorkerProcesses)
			}

			// Since the log config is fixed
			// i'm loading the files set on the rules.yml file
			if strings.HasPrefix(output[c].Name, "log_related") {
				output[c].Parameters[p].Value = output[c].Parameters[p].Notes.Value
			}

			if output[c].Parameters[p].Value == "" {
				output[c].Parameters[p] = nil
			}
		}
	}

	return output
}

func parseRAM(compared string) config.Byte {

	val := extractNumber([]rune(compared))

	switch {
	case strings.HasSuffix(compared, "KB"):
		return val * config.KB
	case strings.HasSuffix(compared, "MB"):
		return val * config.MB
	case strings.HasSuffix(compared, "GB"):
		return val * config.GB
	case strings.HasSuffix(compared, "TB"):
		return val * config.TB
	default:
		return val
	}
}

func extractNumber(val []rune) config.Byte {

	var b bytes.Buffer

	for i := 0; i < len(val); i++ {
		if unicode.IsNumber(val[i]) {
			b.WriteRune(val[i])
		}
	}

	num, err := strconv.Atoi(b.String())

	if err != nil {
		panic(err)
	}

	return config.Byte(num)
}
